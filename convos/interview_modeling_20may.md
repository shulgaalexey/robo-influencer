## Interview Simulation: Manager, Software Development Engineering: Globalisation - Agentic AI

**Date:** May 20, 2025
**Duration:** 25-30 minutes
**Interviewer:** John (Hiring Manager for Globalisation - Agentic AI, Workday)
**Candidate:** Alex Shulga

---

**(0:00) John:** Hi Alex, thanks for joining me today. I’m John, and I’m a Senior Engineering Manager here at Workday, specifically within our Globalisation Agentic AI team. We’re really excited to talk to you about the Manager role. Our team is at the forefront of integrating AI to make Workday’s products feel native to all our global users. Today, I’d like to learn more about your background and experiences, and then you’ll have a chance to ask me any questions. How does that sound?

**(0:01) Alex:** Sounds great, John. Thanks for having me. I’m Alex Shulga, an Engineering Manager with about 15 years of experience, mostly in Big Tech. Most recently, at Microsoft, I led teams building AI-powered developer tools and platforms, including a RAG-based Agentic AI system. I’m particularly drawn to this role at Workday because of its focus on applying Agentic AI to the complex and impactful domain of globalisation.

**(0:02) John:** That’s a very relevant background, Alex. Your experience with RAG-based Agentic AI at Microsoft certainly caught our eye. The job description mentions leading multiple priorities with bold deadlines. Could you share an example of a time you had to manage a complex project with tight deadlines, particularly one involving AI technologies?

**(0:03) Alex:** Certainly. At Microsoft, we were tasked with delivering a new RAG-based Agentic AI chat platform integrated with Microsoft Teams. The goal was to provide intelligent assistance to over 60,000 internal engineers by connecting with over 150 internal tools. We had a firm deadline for a major internal engineering conference.
The complexity lay in the sheer number of integrations, the novelty of the Agentic AI approach for many stakeholders, and the need to ensure scalability and reliability from day one. I led a team of 9 engineers. We broke down the project into parallel workstreams: core RAG pipeline development, individual tool integrations, UX/UI for the Teams app, and robust telemetry. We adopted a Kanban approach with daily stand-ups and bi-weekly stakeholder demos to ensure alignment and rapid feedback. We successfully launched the platform on time, and it was adopted by 25% of the engineering org, saving an estimated 1,500 engineering hours weekly.

**(0:06) John:** That’s an impressive result and a great example of managing a complex AI project. You mentioned stakeholder demos. Our role requires significant collaboration with multi-functional stakeholders – Product, QA, Research, and even customers. How do you approach building relationships and ensuring alignment with such diverse groups, especially when driving innovative AI solutions?

**(0:07) Alex:** Collaboration is key, especially with innovative tech where understanding and buy-in are crucial. My approach is built on transparency, active listening, and finding common ground. For the Agentic AI platform, I established regular syncs with Product Management to refine the vision and prioritize features based on user impact. With QA, we embedded testing early in the development cycle, focusing on both functional and AI-specific metrics like response relevance and agent reliability. For UX, we iterated constantly based on user feedback from early adopter programs.
A specific example was when we were developing the support-deflection AI chatbot. We worked very closely with the support teams for various internal services. We held workshops to understand their common issues, their resolution workflows, and their pain points. This direct engagement ensured the chatbot was trained on relevant data and its responses were genuinely helpful, leading to its success in resolving over 50% of incoming incidents for the services it covered.

**(0:10) John:** That proactive engagement with support teams is a smart approach. The job description also highlights being a coach and mentor. Can you describe your leadership style and how you foster growth and high performance within your engineering teams?

**(0:11) Alex:** I believe in leading with empathy and empowering my team members. My style is a mix of coaching and servant leadership. I strive to create an environment where engineers feel safe to innovate, take risks, and learn from both successes and failures.
At Microsoft, I focused on understanding each team member's career aspirations and aligning their work with those goals where possible. For instance, I had a senior engineer passionate about AI ethics. I created an opportunity for them to lead the development of our responsible AI guidelines for the Agentic AI platform, which was a significant growth opportunity and also benefited the project. I also championed a culture of continuous learning, encouraging participation in conferences, workshops, and internal tech talks. This approach contributed to 6 team member promotions during my tenure there. I also believe in clear expectations, regular feedback, and celebrating successes, big or small.

**(0:14) John:** It’s clear you’re passionate about your team’s development. Let’s switch gears a bit. The role involves understanding and promoting industry best practices. In the context of Agentic AI and globalisation, what do you see as key emerging best practices or challenges?

**(0:15) Alex:** That's a great question. In Agentic AI, especially for globalisation, a key challenge and an area for best practices is ensuring cultural nuance and context are appropriately handled by AI agents. A response that’s helpful in one culture might be ineffective or even inappropriate in another. So, robust evaluation frameworks that go beyond simple accuracy and measure cultural appropriateness are critical.
Another best practice is the 'human-in-the-loop' design, particularly for sensitive localisation tasks. While AI can automate a lot, having mechanisms for human review and correction is vital for quality and for continuously improving the AI models.
Also, ethical considerations around data privacy and bias in AI models become even more complex in a global context due to varying regulations and cultural norms. So, building systems with privacy-preserving techniques and actively working to mitigate bias from the outset is paramount. My experience with RAG architectures has shown that the quality and diversity of the knowledge base are crucial for mitigating some of these issues.

**(0:18) John:** Those are excellent points, Alex, especially regarding cultural nuance and human-in-the-loop. It aligns well with our thinking in the Globalisation team.
Now, I’d like to open it up for you. What questions do you have for me about the role, the team, or Workday?

**(0:19) Alex:** Thanks, John. I do have a few. I’ve read about Workday’s Globalization organization and its mission to make products feel native globally. Could you elaborate on how this new Agentic AI focus within Globalisation is expected to enhance or transform the existing internationalisation and localisation frameworks and platforms?

**(0:20) John:** That’s a very insightful question. The Agentic AI initiative is seen as a significant accelerator and a way to add deeper intelligence to our globalisation efforts. For example, instead of just rule-based localisation, we envision AI agents that can understand the *intent* behind content and adapt it more dynamically and contextually for different locales. This could apply to everything from UI text to complex regulatory content. We also see Agentic AI playing a big role in automating and improving the quality of our translation pipelines, perhaps by having agents that can learn from linguist feedback in a more sophisticated way or even assist with terminology governance.

**(0:22) Alex:** That sounds fascinating. The documentation I found mentions a "Globalisation Platform Engineering (GPE)" team and an "AI Language Technology" unit. How does this specific Manager role for "Globalisation - Agentic AI" fit within that structure, and what would be the primary interaction points with these other units?

**(0:23) John:** Good question. This role is central to the "AI Language Technology" unit but will work extremely closely with GPE. Think of GPE as providing the foundational globalisation services and APIs. Your team would build the AI agents and intelligent services that leverage and extend what GPE offers. So, a primary interaction would be with GPE to understand their capabilities, define requirements for new AI-enabling features in their platform, and then integrate your team’s AI solutions. You'd also collaborate with the "Global Content & Localisation Ops" team to understand their needs, get feedback on AI tool effectiveness, and ensure your solutions meet their quality and operational requirements.

**(0:25) Alex:** That clarifies the structure well. One last question: the job description mentions "co-ordinating the analysis, design, programming, debugging, and improvement of high-quality, innovative solutions." Given the innovative nature of Agentic AI, how does Workday balance the need for rapid iteration and experimentation with the high-quality and reliability standards expected for enterprise applications?

**(0:26) John:** That’s a constant balancing act, and a critical one. We encourage innovation and experimentation, often using techniques like A/B testing, canary releases, and feature flags, especially for new AI-driven features. We have a strong culture of quality, so robust testing, including performance and security testing, is integral to our development lifecycle. For AI specifically, we're also building out more sophisticated monitoring and evaluation frameworks to track model performance and user experience in production. The idea is to allow for rapid learning and iteration in controlled environments before rolling out broadly, ensuring that innovation doesn’t come at the cost of the enterprise-grade reliability our customers expect.

**(0:28) Alex:** That makes a lot of sense. Thanks, John, that’s been very helpful and gives me a much clearer picture of the role and the exciting challenges involved.

**(0:29) John:** You’re welcome, Alex. It was great speaking with you today and learning more about your experience. Your background in Agentic AI and leading engineering teams seems like a strong fit. Our recruiter will be in touch regarding the next steps in the process.

**(0:30) Alex:** Thank you, John. I really appreciate your time and enjoyed our conversation. I look forward to hearing about the next steps.

---